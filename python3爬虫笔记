Python3构造爬虫
	首先下载request库(通过Python自带的pip包管理器即可下载)
		request库可以完成网页请求的伪造，有八个主要方法
			.request()
			.get()
			.put()
			.head()
			.post()
			.patch()
			.delete()
		
	1.get()方法
		常用request.get(url)得到一个指定网站的响应对象，得到的对象是response对象
		response对象有五个常用属性
			.statu_code:返回状态码，200，404等
			.text：响应的字符串形式，即页面内容
			.encoding:从header中获取的响应内容编码
			.apparent_encoding:从内容中分析的响应内容编码
			.content:响应内容的二进制形式
	2.代码框架
		由于网络连接并不总是有效的，所以往往会出现各种异常，如何处理这些异常至关重要
		常见的异常有六种
		ConnectionError
		HTTPError
		URLRequired
		TooManyRedirects
		ConnectTimeout
		Timeout
		一般返回时会使用r.raise_for_status()对返回码进行判断，若不是两百，则会产生一个异常
		这组成了我们的通用代码框架：
			先get,在判断是否产生异常，若产生则处理异常，否则正常处理数据。
			
	3.request和http基础常识
		当request向post一个键值对时，键值对会默认存储到表单(form)中。
		request所有方法都是在调用request方法实现的
		request有一些可选参数，需要使用http域名=参数来调用(Python的语法？)
		http域参数都是request方法的特殊访问参数，如设置代理服务器，特定的请求部分，SSL配置等
		
	4.robots协议
		由于网络爬虫存在信息泄漏，资源负荷加重，法律风险三方面问题，国际规定了Robots协议用于
		限制网络爬虫
		限制网络爬虫的方法有两种：
			1.读取User-Argen属性，只给受信IP或浏览器发数据
			2.在网站根目录下设置robots.txt，但是不是强制遵守，如果访问量小，原则上可以不遵守
			
	5.实例分析：
		亚马逊商品爬取：未修改头部信息时，会出现500的返回，因为亚马逊对用户头部进行了判别认证
						需要修改请求头部，模仿浏览器
		提交百度/360的搜索关键字：百度的搜索接口为wd,360的搜索接口为q，所以在url中添加对应的
									参数与关键字即可进行搜索，但是记得在/s目录下进行搜索
		网络图片的爬取：一般的网络图片的链接格式为地址/picture名.jpg，我们只需要对结尾为jpg
						的文件进行爬取保存即可，并以二进制保存。
		IP地址归属地的查询：ip138网站可以让用户进行IP地址的归属地查询，其表单未经过加密处理
							所以可以直接利用，格式为http://m.ip138.com/ip.asp?ip=
							在后面加上IP地址即可(现在似乎已失效)
Http标签的解析
	BeautifulSoup库可以帮助对http标签进行解析，使用pip进行下载即可
	1.基础用法
		基础使用bs4库只需要两行代码
			from bs4 import BeautifulSoup
			soup = BeautifulSoup(需要解析的内容(demo),解析指引(html.parser))
			使用print(soup.prettify())即可格式化输出
			prettify()可以让HTML标签以更友好的方式显示出来
			bs4库默认的编码为UTF-8，与python3解释器的编码相同
	2.基本元素
		BeautifulSoup类是由页面标签树转换来的，BeautifulSoup库自带HTML解析器，使用方法如
			上一节的实例代码(html.praser)，也可以安装其他的解析器，如lxml解析器，同样通过
			BeautifulSoup类调用，解析html文档时，解析器设置"lxml",解析xml文档时，解析器设置
			"xml"。又如html5lib解析器，解析html文档时，设置"html5lib"
		Tag元素：标签，也是页面的基本组成单元，可以使用soup.tag获得，当文档中存在多个同名
					标签时，只会返回第一个该名称的标签。Tag标签的返回值类型为bs4库中的Tag
					类型
		Name元素：标签的名字，<tag>.name
		Attributes元素:标签的属性，数据类型为字典，<tag>.attrs
		NavigableString元素：标签内的非属性字符串，即内容，<tag>.string，可以跨越多个标签层次
							即子标签的内容不会被返回
		Comment元素：标签内的注释,也可以通过string被得到，但是得到之后返回值类型为Comment

	3.基于bs4库的HTML元素遍历方法
		HTML页面是一个标签树，树形结构有三种遍历方式：下行遍历(从根节点开始遍历)，上行遍历
														(从叶子节点开始遍历)，平行遍历(平级
														节点之间遍历)
			虽然树形结构叫标签树，但是NavigableString也是一个标签树节点，遍历时需要注意处理
			下行遍历：
				下行遍历相关的属性有三个
					.contents:子节点列表，将<tag>的所有儿子节点存入列表
					.children：子节点的迭代类型，与.content类似，但是需要迭代使用
					.descendants:子孙节点的迭代类型，可以获得当前节点下的所有节点
			上行遍历：
				上行遍历相关的属性有两个
					.parent:节点的父标签
					.parents:节点先辈标签的迭代类型
					soup是特殊的标签，它没有父标签，所以要做特殊处理
			平行遍历：
				平行遍历相关的属性有四个
					.next_sibling:平行的下一个标签(需在同一个父标签下)
					.previous_sibling:平行的前一个标签
					.next_siblings:平行前序标签的迭代类型
					.previous_siblings:平行后续标签的迭代类型
					
	4.信息的标记形式
		现在网络公认的信息标记形式有三种：XML，JSON，YAML
		1.XML:使用标签对信息进行标记，标签可以有属性和内容，也可以为空，可以将HTML理解为一种
				特殊的XML
		2.JSON：使用键值对的形式表示信息，但若键值中的一方是字符串，必须用双引号标识(说明有
					数据类型)。当一个键对应多个值时，采用键:[值1,值2]来表示。
					键值对可以嵌套使用，使用大括号体现嵌套关系，如
					键1:{
						子键1:子值1,
						子键2:子值2
					}
		3.YAML：无数据类型的键值对，使用缩进代表包含关系(类似Python)，用-表达并列关系
				用|表达接下来整段的数据，用#表达对当前键的注释
	
	5.信息提取的一般方法
		全部解析后查找指定内容：准确度高，但是速度慢
		不关注整体结构，直接使用文本搜索函数查找内容：速度快，但准确度与信息内容关联度大
		一般会将两种方法结合使用
			例：想要找到页面内所有的链接，可以先用文本搜索检索a标签，然后解析a标签，提取
				href属性
		1.bs4查找页面信息相关方法
			.find_all(name,attrs,recursive,string):
				name参数为标签名，若希望查找多个标签，则可以使用数组进行输入，若希望查找
				所有标签，则可以输入参数True
				若希望查找指定字母开头/含有指定字母的标签，则需要引入正则表达式库(import re)
				attrs标签为属性值字符串，指定含有某属性值的指定名称标签
				recursive指定是否检索当前标签的所有子孙信息，默认为true
				string是在<>...</>中字符串区域检索指定字符串
				<tag>()在bs4中等价于<tag>.find_all()，这是一种简写形式
				
			find_all()方法有七个扩展方法，参数列表与find_all()相同	
				
